import { QueryCommand, PutCommand } from "@aws-sdk/lib-dynamodb";
import { DynamoDBClient } from "@aws-sdk/client-dynamodb";
import { v4 as uuidv4 } from "uuid";
import { createAllConversations } from "../scripts/create_conversations.js";
import dotenv from "dotenv";
import fs from "fs";
import path from "path";

dotenv.config();

const dynamoDbClient = new DynamoDBClient({
  region: "us-east-1",
});

/**
 * Parse command line arguments
 */
function parseArguments() {
  const args = process.argv.slice(2);
  const config = {
    userId: "24c844c8-6031-702b-8de2-f521e7104fae",
    assistantId: "0186f1fa-ded1-45ff-a7cf-20d7807ac429", 
    baseUrl: "http://localhost:3005",
    stage: "myenv",
    maxRetries: 3,
    retryDelay: 2000,
    // New parameters for conversation creation
    maxConversations: 20, // --max-count / -m
    maxConversationsToTest: undefined, // --test-count / -t (test all by default)
    preview: false, // --preview / -p
    skipConversationCreation: false, // --skip-create / -s
  };

  for (let i = 0; i < args.length; i++) {
    const arg = args[i];
    const nextArg = args[i + 1];

    switch (arg) {
      case '--assistant-id':
      case '-a':
        if (nextArg) config.assistantId = nextArg;
        i++;
        break;
      case '--user-id':
      case '-u':
        if (nextArg) config.userId = nextArg;
        i++;
        break;
      case '--stage':
      case '-s':
        if (nextArg) config.stage = nextArg;
        i++;
        break;
      case '--max-count':
      case '-m':
        if (nextArg) config.maxConversations = parseInt(nextArg);
        i++;
        break;
      case '--test-count':
      case '-t':
        if (nextArg) config.maxConversationsToTest = parseInt(nextArg);
        i++;
        break;
      case '--base-url':
      case '-b':
        if (nextArg) config.baseUrl = nextArg;
        i++;
        break;
      case '--preview':
      case '-p':
        config.preview = true;
        break;
      case '--skip-create':
      case '--skip-creation':
        config.skipConversationCreation = true;
        break;
      case '--help':
      case '-h':
        console.log(`
ğŸš€ RAG Validation System - Command Line Options

USAGE:
  node tests/ragValidation.js [options]

OPTIONS:
  -a, --assistant-id <id>     Assistant ID to test (default: 0186f1fa-ded1-45ff-a7cf-20d7807ac429)
  -u, --user-id <id>          User ID for testing (default: 24c844c8-6031-702b-8de2-f521e7104fae)  
  -s, --stage <stage>         DynamoDB stage (default: myenv)
  -m, --max-count <num>       Max conversations to create (default: 20)
  -t, --test-count <num>      Max conversations to test (default: test all created)
  -b, --base-url <url>        RAG system base URL (default: http://localhost:3005)
  -p, --preview               Preview mode - don't create actual conversations
      --skip-create           Skip conversation creation, use existing conversations
  -h, --help                  Show this help message

EXAMPLES:
  # Run with default settings
  node tests/ragValidation.js

  # Create 5 conversations and test only 2 of them
  node tests/ragValidation.js --max-count 5 --test-count 2

  # Test different assistant with custom stage
  node tests/ragValidation.js -a 86804a79-61e4-408a-9623-2eac4b43fe97 -s dev

  # Preview mode (don't create conversations)
  node tests/ragValidation.js --preview --max-count 3

  # Skip conversation creation, test existing conversations
  node tests/ragValidation.js --skip-create --test-count 1
        `);
        process.exit(0);
        break;
    }
  }

  return config;
}

// Parse command line arguments and create CONFIG
const CONFIG = parseArguments();

// Embedding cache for expected answers (they don't change)
const EMBEDDING_CACHE = new Map();

// Banking questions based on "Ticari MÃ¼ÅŸterilerden AlÄ±nabilecek Azami Ãœcretler" tariff
const BANKING_QUESTIONS = [
  {
    id: 1,
    question:
      "Bir banka ticari krediler iÃ§in ilk kredi tahsisi (Kredi Tahsis) sÄ±rasÄ±nda azami hangi yÃ¼zde oranÄ±nda Ã¼cret alabilir?",
    expectedAnswer: "%0,25 â€“ onaylanan limitin %0,25'i",
    testType: "factual_recall",
    purpose: "Oturumu net bir gerÃ§ek bilgi ile baÅŸlatÄ±n",
  },
  {
    id: 2,
    question:
      "AynÄ± kredide limit yenileme durumunda uygulanabilecek Ã¼cret yÃ¼zdesi nedir?",
    expectedAnswer: "%0,125 â€“ yenilenen limitin %0,125'i",
    testType: "short_term_memory",
    purpose: "Soru 1'e yakÄ±n; kÄ±sa sÃ¼reli bellek kontrolÃ¼",
  },
  {
    id: 3,
    question:
      "Kredi KullandÄ±rÄ±m Ãœcreti (kredi serbest bÄ±rakma) azami kaÃ§ yÃ¼zde olabilir?",
    expectedAnswer:
      "%1,1 â€“ kullandÄ±rÄ±lan tutarÄ±n %1,1'i (â‰¤ 1 yÄ±l vadede yÄ±llÄ±klandÄ±rÄ±lmÄ±ÅŸ)",
    testType: "topic_continuity",
    purpose: "AynÄ± alt baÅŸlÄ±kta devam",
  },
  {
    id: 4,
    question:
      "Bir ÅŸirket Ä°tibar / Niyet / Referans mektubu talep ettiÄŸinde asgari ve azami Ã¼cretler nelerdir?",
    expectedAnswer: "Asgari â‚º500, azami â‚º10 000 (BSMV hariÃ§)",
    testType: "fixed_fee_range",
    purpose: "DÃ¼z tutarlÄ± Ã¼cret; konu deÄŸiÅŸmeden hatÄ±rlamayÄ± test eder",
  },
  {
    id: 5,
    question:
      "Ekspertiz / Teminat Tesis hizmeti iÃ§in uygulanabilecek Ã¼cret aralÄ±ÄŸÄ± nedir?",
    expectedAnswer: "â‚º2 700 â€“ â‚º341 000, maliyet + %15'i aÅŸmamak kaydÄ±yla",
    testType: "numerical_accuracy",
    purpose: "SayÄ±sal doÄŸruluk testi",
  },
  {
    id: 6,
    question:
      "Kredi yapÄ±landÄ±rma veya faiz oranÄ± deÄŸiÅŸikliÄŸi iÃ§in azami Ã¼cret yÃ¼zdesi kaÃ§tÄ±r?",
    expectedAnswer: "%5 â€“ kredi tutarÄ± Ã¼zerinden yÄ±llÄ±k",
    testType: "topic_retention",
    purpose: "YanlÄ±ÅŸ yÃ¶nlendirme olmadan konuyu korumasÄ± beklenir",
  },
  {
    id: 7,
    question:
      "MÃ¼ÅŸteri taahhÃ¼t edilen krediyi kullanmazsa (TaahhÃ¼de Uymama) alÄ±nabilecek yÄ±llÄ±k azami Ã¼cret yÃ¼zdesi nedir?",
    expectedAnswer: "%3 â€“ kullanÄ±lmayan tutar Ã¼zerinden",
    testType: "logical_connection",
    purpose: "Soru 6 ile mantÄ±ksal eÅŸleÅŸme",
  },
  {
    id: 8,
    question:
      "Gayrinakdi Kredi â€“ DÃ¶nem Ãœcreti iÃ§in asgari Ã¼cret ve azami yÄ±llÄ±k yÃ¼zde nedir?",
    expectedAnswer: "Asgari â‚º1 000; azami %5 yÄ±llÄ±k",
    testType: "topic_coherence",
    purpose: "AynÄ± bÃ¶lÃ¼mde konu bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ sÃ¼rdÃ¼rÃ¼r",
  },
  {
    id: 9,
    question:
      "1 Mart 2021'den Ã¶nce kullandÄ±rÄ±lmÄ±ÅŸ sabit faizli TL kredilerde (â‰¤ 24 ay kalan) erken kapamada azami erken Ã¶deme Ã¼creti nedir?",
    expectedAnswer: "%1 â€“ kalan anapara Ã¼zerinden",
    testType: "date_sensitive_logic",
    purpose: "Tarih duyarlÄ± mantÄ±k testi",
  },
  {
    id: 10,
    question:
      "Mobil/Ä°nternet bankacÄ±lÄ±ÄŸÄ±ndan, tutarÄ± â‚º6 300'a kadar olan EFT iÅŸlemleri iÃ§in azami Ã¼cret ne kadardÄ±r?",
    expectedAnswer: "â‚º6,09 (BSMV hariÃ§)",
    testType: "topic_transition",
    purpose: "Kredi konusundan Ã¶demelere geÃ§iÅŸ â€“ konu takibi",
  },
  {
    id: 11,
    question:
      "AynÄ± kanal ve tutar aralÄ±ÄŸÄ±nda yapÄ±lan Havale iÅŸlemlerinde azami Ã¼cret ne kadardÄ±r?",
    expectedAnswer: "â‚º3,05 (BSMV hariÃ§)",
    testType: "concept_differentiation",
    purpose: "Benzer kavram, doÄŸru ayÄ±rmasÄ± beklenir",
  },
  {
    id: 12,
    question:
      "Fiziksel POS cihazÄ± iÃ§in donanÄ±m/yazÄ±lÄ±m yÄ±llÄ±k bakÄ±m Ã¼creti azami ne kadardÄ±r?",
    expectedAnswer: "â‚º489 (BSMV hariÃ§)",
    testType: "long_term_memory",
    purpose:
      "Oturumu uzak bir konu ile sonlandÄ±rÄ±n, uzun vadeli bellek testi iÃ§in",
  },
];

/**
 * Save results to logs
 */
function saveTestResults(userId, testType, results) {
  const timestamp = new Date();
  const dateStr = timestamp.toISOString().split("T")[0];
  const timeStr = timestamp
    .toISOString()
    .split("T")[1]
    .split(".")[0]
    .replace(/:/g, "-");
  const filename = `${testType}_${userId}_${dateStr}_${timeStr}.json`;
  const logsDir = path.join(process.cwd(), "logs");
  const filepath = path.join(logsDir, filename);

  if (!fs.existsSync(logsDir)) {
    fs.mkdirSync(logsDir, { recursive: true });
  }

  const logData = {
    testType,
    userId,
    timestamp: timestamp.toISOString(),
    testConfiguration: CONFIG,
    results,
    metadata: {
      nodeVersion: process.version,
      platform: process.platform,
      testDuration: results.executionTime || "N/A",
    },
  };

  try {
    fs.writeFileSync(filepath, JSON.stringify(logData, null, 2), "utf8");
    console.log(`ğŸ“ Results saved to: ${filepath}`);
    return filepath;
  } catch (error) {
    console.error(`âŒ Error saving results: ${error.message}`);
    return null;
  }
}

/**
 * Send question to RAG system
 */
async function sendRAGQuestion(question, questionId, conversationId, userInput) {
  const messageId = uuidv4();
  const timestamp = new Date().toISOString();

  // Store user message
  const userMessage = {
    conversationId: conversationId,
    createdAt: timestamp,
    content: `TEST MODUNA GEC ${question}`,
    role: "user",
    userId: CONFIG.userId,
    assistantId: CONFIG.assistantId,
    identifier: messageId,
    type: "default",
    isGptSuitable: true,
    assistantGroupId: "7c68ad5d-6092-4a4a-98bc-235e4553e332",
    userInput: userInput,
  };

  try {
    await dynamoDbClient.send(
      new PutCommand({
        TableName: `UpConversationMessage-${CONFIG.stage}`,
        Item: userMessage,
      })
    );

    console.log(`ğŸ“¡ Question ${questionId}: ${question.substring(0, 80)}...`);

    const response = await fetch(
      `${CONFIG.baseUrl}/user/${CONFIG.userId}/conversation/${conversationId}/whatToAsk/stream`,
      {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          query: `TEST MODUNA GEC ${question}`,
          assistantId: CONFIG.assistantId,
          stage: CONFIG.stage,
        }),
      }
    );

    if (!response.ok) {
      throw new Error(
        `Request failed: ${response.status} ${response.statusText}`
      );
    }

    // Read streaming response
    let fullContent = "";
    const reader = response.body.getReader();
    const decoder = new TextDecoder();

    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      const chunk = decoder.decode(value);
      fullContent += chunk;
      if (chunk.includes("[DONE-UP]")) break;
    }

    const cleanContent = fullContent.replace("[DONE-UP]", "").trim();
    console.log(`âœ… Response received (${cleanContent.length} chars)`);

    // Save assistant response to messages table
    if (cleanContent) {
      const assistantMessageId = uuidv4();
      const assistantTimestamp = new Date().toISOString();

      const assistantMessage = {
        conversationId: conversationId,
        createdAt: assistantTimestamp,
        content: cleanContent,
        role: "assistant",
        userId: CONFIG.userId,
        assistantId: CONFIG.assistantId,
        identifier: assistantMessageId,
        type: "default",
        isGptSuitable: true,
        assistantGroupId: "7c68ad5d-6092-4a4a-98bc-235e4553e332",
        userInput: userInput,
        metadata: {
          questionId: questionId,
          testMode: true,
          responseType: "rag_validation",
        },
      };

      try {
        await dynamoDbClient.send(
          new PutCommand({
            TableName: `UpConversationMessage-${CONFIG.stage}`,
            Item: assistantMessage,
          })
        );
        console.log(`ğŸ’¾ Assistant response saved to messages table`);
      } catch (saveError) {
        console.error(
          `âš ï¸ Failed to save assistant response: ${saveError.message}`
        );
      }

      return {
        success: true,
        content: cleanContent,
        timestamp,
        userMessage,
        assistantMessage,
      };
    }

    return {
      success: true,
      content: cleanContent,
      timestamp,
      userMessage,
    };
  } catch (error) {
    console.error(`âŒ Error for question ${questionId}: ${error.message}`);
    return {
      success: false,
      content: "",
      error: error.message,
      timestamp,
      userMessage,
    };
  }
}

/**
 * Generate text embeddings using Azure OpenAI with caching
 */
async function generateEmbedding(text, useCache = true) {
  // Check cache first
  if (useCache && EMBEDDING_CACHE.has(text)) {
    console.log("ğŸ“‹ Using cached embedding");
    return EMBEDDING_CACHE.get(text);
  }

  const azureEndpoint = process.env.AZURE_OPENAI_ENDPOINT;
  const azureApiKey = process.env.AZURE_OPENAI_KEY;
  const azureApiVersion = "2024-02-15-preview";

  if (!azureEndpoint || !azureApiKey) {
    throw new Error("Missing Azure OpenAI configuration for embeddings");
  }

  try {
    const url = `${azureEndpoint}/openai/deployments/text-embedding-ada-002/embeddings?api-version=${azureApiVersion}`;

    const response = await fetch(url, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "api-key": azureApiKey,
      },
      body: JSON.stringify({
        input: text,
        encoding_format: "float",
      }),
    });

    if (!response.ok) {
      throw new Error(`Azure Embedding API error: ${response.status}`);
    }

    const data = await response.json();
    const embedding = data.data[0].embedding;

    // Cache the result
    if (useCache) {
      EMBEDDING_CACHE.set(text, embedding);
    }

    return embedding;
  } catch (error) {
    console.error("Embedding generation error:", error);
    return null;
  }
}

/**
 * Calculate cosine similarity between two vectors
 */
function calculateCosineSimilarity(vectorA, vectorB) {
  if (!vectorA || !vectorB || vectorA.length !== vectorB.length) {
    return 0;
  }

  let dotProduct = 0;
  let normA = 0;
  let normB = 0;

  for (let i = 0; i < vectorA.length; i++) {
    dotProduct += vectorA[i] * vectorB[i];
    normA += vectorA[i] * vectorA[i];
    normB += vectorB[i] * vectorB[i];
  }

  if (normA === 0 || normB === 0) {
    return 0;
  }

  return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
}

/**
 * Extract numerical values for exact matching
 */
function extractNumericalInfo(text) {
  const info = {
    percentages: [],
    amounts: [],
    hasBSMV: false,
    hasYillik: false,
  };

  // Extract percentages (%, yÃ¼zde)
  const percentageRegex = /%?\s*(\d+[,.]?\d*)\s*[%yÃ¼zde]/gi;
  let match;
  while ((match = percentageRegex.exec(text)) !== null) {
    info.percentages.push(parseFloat(match[1].replace(",", ".")));
  }

  // Extract amounts (â‚º, TL, lira)
  const amountRegex = /[â‚ºTL]\s*(\d+[,.]?\d*)|(\d+[,.]?\d*)\s*[â‚ºTLlira]/gi;
  while ((match = amountRegex.exec(text)) !== null) {
    const amount = match[1] || match[2];
    info.amounts.push(parseFloat(amount.replace(",", ".")));
  }

  // Check for BSMV mentions
  info.hasBSMV = /bsmv|bddk|vergi/gi.test(text);

  // Check for yearly mentions
  info.hasYillik = /yÄ±llÄ±k|yÄ±lda|annual/gi.test(text);

  return info;
}

/**
 * Calculate numerical accuracy score
 */
function calculateNumericalAccuracy(expectedInfo, actualInfo) {
  let score = 0;
  let totalChecks = 0;

  // Check percentage accuracy
  if (expectedInfo.percentages.length > 0) {
    totalChecks++;
    const expectedPercentages = expectedInfo.percentages.sort();
    const actualPercentages = actualInfo.percentages.sort();

    if (expectedPercentages.length === actualPercentages.length) {
      let percentageMatches = 0;
      for (let i = 0; i < expectedPercentages.length; i++) {
        if (Math.abs(expectedPercentages[i] - actualPercentages[i]) < 0.01) {
          percentageMatches++;
        }
      }
      score += percentageMatches / expectedPercentages.length;
    }
  }

  // Check amount accuracy
  if (expectedInfo.amounts.length > 0) {
    totalChecks++;
    const expectedAmounts = expectedInfo.amounts.sort();
    const actualAmounts = actualInfo.amounts.sort();

    if (expectedAmounts.length === actualAmounts.length) {
      let amountMatches = 0;
      for (let i = 0; i < expectedAmounts.length; i++) {
        if (Math.abs(expectedAmounts[i] - actualAmounts[i]) < 1) {
          amountMatches++;
        }
      }
      score += amountMatches / expectedAmounts.length;
    }
  }

  // Check BSMV mention consistency
  if (expectedInfo.hasBSMV || actualInfo.hasBSMV) {
    totalChecks++;
    score += expectedInfo.hasBSMV === actualInfo.hasBSMV ? 1 : 0;
  }

  return totalChecks > 0 ? score / totalChecks : 1;
}

/**
 * Enhanced semantic evaluation with embeddings
 */
async function evaluateWithSemantics(expectedAnswer, actualAnswer) {
  try {
    // Generate embeddings (cache expected answers, don't cache actual answers)
    console.log("ğŸ”„ Generating embeddings...");
    const [expectedEmbedding, actualEmbedding] = await Promise.all([
      generateEmbedding(expectedAnswer, true), // Cache expected answer
      generateEmbedding(actualAnswer, false), // Don't cache actual answer
    ]);

    if (!expectedEmbedding || !actualEmbedding) {
      return {
        similarity: 0,
        score: 0,
        numerical_accuracy: 0,
        error: "Failed to generate embeddings",
      };
    }

    // Calculate cosine similarity
    const similarity = calculateCosineSimilarity(
      expectedEmbedding,
      actualEmbedding
    );

    // Extract and compare numerical information
    const expectedInfo = extractNumericalInfo(expectedAnswer);
    const actualInfo = extractNumericalInfo(actualAnswer);
    const numericalAccuracy = calculateNumericalAccuracy(
      expectedInfo,
      actualInfo
    );

    // Convert similarity to score (0-10)
    const semanticScore = Math.round(similarity * 10 * 10) / 10;

    // Weighted score: 70% semantic similarity + 30% numerical accuracy
    const combinedSemanticScore =
      Math.round((similarity * 0.7 + numericalAccuracy * 0.3) * 10 * 10) / 10;

    return {
      similarity: Math.round(similarity * 1000) / 1000,
      score: combinedSemanticScore,
      semantic_score: semanticScore,
      numerical_accuracy: Math.round(numericalAccuracy * 1000) / 1000,
      numerical_info: {
        expected: expectedInfo,
        actual: actualInfo,
      },
      threshold_met: similarity >= 0.6,
    };
  } catch (error) {
    console.error("Semantic evaluation error:", error);
    return {
      similarity: 0,
      score: 0,
      numerical_accuracy: 0,
      error: error.message,
    };
  }
}


/**
 * Semantic-only evaluation with AI feedback (no AI scoring)
 */
async function evaluateWithSemanticSystem(
  question,
  expectedAnswer,
  actualAnswer
) {
  console.log("ğŸ”„ Running semantic evaluation with AI feedback...");

  try {
    // Run both evaluations in parallel
    const [aiEvaluation, semanticEvaluation] = await Promise.all([
      evaluateWithAI(question, expectedAnswer, actualAnswer),
      evaluateWithSemantics(expectedAnswer, actualAnswer),
    ]);

    // Use semantic score as the primary score
    const finalScore = semanticEvaluation.score;

    // Determine overall assessment based on semantic score only
    const threshold_met = semanticEvaluation.threshold_met;

    return {
      ai_evaluation: {
        evaluation: aiEvaluation.evaluation,
        coaching: aiEvaluation.coaching,
        full_evaluation: aiEvaluation.full_evaluation,
      },
      semantic_evaluation: semanticEvaluation,
      final_score: finalScore,
      evaluation_breakdown: {
        semantic_score: semanticEvaluation.score,
        similarity: semanticEvaluation.similarity,
        numerical_accuracy: semanticEvaluation.numerical_accuracy,
        scoring_method: "semantic_only",
      },
      threshold_met: threshold_met,
      overall_assessment:
        finalScore >= 8
          ? "EXCELLENT"
          : finalScore >= 6
          ? "GOOD"
          : finalScore >= 4
          ? "FAIR"
          : "NEEDS IMPROVEMENT",
    };
  } catch (error) {
    console.error("Semantic evaluation error:", error);
    return {
      ai_evaluation: {
        evaluation: "AI evaluation failed",
        coaching: "",
        full_evaluation: "",
      },
      semantic_evaluation: { score: 0, similarity: 0, error: error.message },
      final_score: 0,
      error: error.message,
    };
  }
}

/**
 * AI-powered evaluation using Azure OpenAI
 */
async function evaluateWithAI(question, expectedAnswer, actualAnswer) {
  const azureEndpoint = process.env.AZURE_OPENAI_ENDPOINT;
  const azureApiKey = process.env.AZURE_OPENAI_KEY;
  const azureDeployment = process.env.AZURE_OPENAI_API_DEPLOYMENT_NAME;
  const azureApiVersion = "2024-02-15-preview";

  if (!azureEndpoint || !azureApiKey || !azureDeployment) {
    console.error("âŒ Missing Azure OpenAI configuration");
    return {
      score: 0,
      evaluation: "Azure configuration missing",
      full_evaluation: "Missing Azure OpenAI environment variables",
    };
  }

  const evaluationPrompt = `
Sen bir ticari bankacÄ±lÄ±k uzmanÄ± ve mevzuat denetmenisin. AÅŸaÄŸÄ±daki mÃ¼ÅŸteri temsilcisi cevabÄ±nÄ± "SADECE FAKTÃœEL DOÄRULUK" aÃ§Ä±sÄ±ndan deÄŸerlendir:

MÃœÅTERI SORUSU: ${question}
BEKLENEN YANIT (Resmi Tarife): ${expectedAnswer}
MÃœÅTERI TEMSÄ°LCÄ°SÄ° CEVABI: ${actualAnswer}

FAKTÃœEL DOÄRULUK KRÄ°TERLERÄ° (WUP-832):
1. **RAKAMSAL DOÄRULUK**: Verilen yÃ¼zdeler, tutarlar, limitler tam olarak doÄŸru mu?
   - Ã–rn: "%0,25" yerine "%0,3" yazmÄ±ÅŸ mÄ±?
   - Ã–rn: "â‚º6,09" yerine "â‚º6,10" yazmÄ±ÅŸ mÄ±?

2. **MEVZUAT UYGUNLUÄU**: "Ticari MÃ¼ÅŸterilerden AlÄ±nabilecek Azami Ãœcretler" tarifesine birebir uyumluluk
   - BSMV dahil/hariÃ§ bilgisi doÄŸru mu?
   - Azami/asgari limitler doÄŸru mu?
   - Vade/tutar aralÄ±klarÄ± doÄŸru mu?

3. **SPESÄ°FÄ°K BÄ°LGÄ° VALÄ°DASYONU**: Ã–zellikle kesin oranlar ve tutarlar iÃ§in
   - "6300 Lira altÄ±ndaki nakit yÃ¶netimi Ã¼creti nedir?" â†’ "30,46 Lira"
   - Bu tÃ¼r spesifik bilgiler tam doÄŸru verilmiÅŸ mi?

4. **FAKTÃœEL TUTARLILIK**: Beklenen yanÄ±t ile gerÃ§ek yanÄ±t arasÄ±nda faktÃ¼el fark var mÄ±?
   - HiÃ§bir sayÄ±sal hata tolere edilmez
   - Mevzuat terimlerinde kesinlik ÅŸart

**Ã–NEMLÄ°**: Bu deÄŸerlendirme SADECE faktÃ¼el doÄŸruluÄŸa odaklanÄ±r. Dil kalitesi, mÃ¼ÅŸteri deneyimi gibi faktÃ¶rler deÄŸerlendirilmez.

FAKTÃœEL DOÄRULUK PUANI: [1-10]
DEÄERLENDÄ°RME: [Sadece faktÃ¼el doÄŸruluk aÃ§Ä±sÄ±ndan kÄ±sa aÃ§Ä±klama]
KOÃ‡LUK: [FaktÃ¼el hatalar iÃ§in dÃ¼zeltme Ã¶nerileri]`;

  try {
    const url = `${azureEndpoint}/openai/deployments/${azureDeployment}/chat/completions?api-version=${azureApiVersion}`;

    const response = await fetch(url, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "api-key": azureApiKey,
      },
      body: JSON.stringify({
        messages: [
          {
            role: "system",
            content:
              "Sen bir ticari bankacÄ±lÄ±k uzmanÄ±sÄ±n ve mÃ¼ÅŸteri temsilcisi yanÄ±tlarÄ±nÄ± 'Ticari MÃ¼ÅŸterilerden AlÄ±nabilecek Azami Ãœcretler' tarifesine gÃ¶re deÄŸerlendiriyorsun.",
          },
          { role: "user", content: evaluationPrompt },
        ],
        max_tokens: 800,
        temperature: 0.1,
      }),
    });

    if (!response.ok) {
      throw new Error(`Azure API error: ${response.status}`);
    }

    const data = await response.json();
    const evaluation = data.choices[0].message.content;

    // Extract score, evaluation, and coaching (updated for WUP-832 prompt structure)
    const scoreMatch = evaluation.match(/\*?\*?FAKTÃœEL DOÄRULUK PUANI:\*?\*?\s*(\d+)/) || 
                      evaluation.match(/\*?\*?PUAN:\*?\*?\s*(\d+)/);
    const evalMatch = evaluation.match(/\*?\*?DEÄERLENDÄ°RME:\*?\*?\s*(.+?)(?=\*?\*?KOÃ‡LUK:|$)/s);
    const coachingMatch = evaluation.match(/\*?\*?KOÃ‡LUK:\*?\*?\s*(.+)/s);

    const score = scoreMatch ? parseInt(scoreMatch[1]) : 0;
    const evalText = evalMatch ? evalMatch[1].trim() : evaluation;
    const coaching = coachingMatch ? coachingMatch[1].trim() : "";

    return {
      score,
      evaluation: evalText,
      coaching: coaching,
      full_evaluation: evaluation,
    };
  } catch (error) {
    console.error("AI evaluation error:", error);
    return {
      score: 0,
      evaluation: "AI evaluation failed",
      full_evaluation: error.message,
    };
  }
}

/**
 * Pre-cache embeddings for expected answers
 */
async function preCacheExpectedAnswers() {
  console.log("ğŸ“‹ Pre-caching embeddings for expected answers...");
  const expectedAnswers = BANKING_QUESTIONS.map((q) => q.expectedAnswer);

  // Generate embeddings for all expected answers in parallel
  await Promise.all(
    expectedAnswers.map((answer) => generateEmbedding(answer, true))
  );

  console.log(`âœ… Cached ${EMBEDDING_CACHE.size} embeddings`);
}

/**
 * Run simplified RAG validation with conversation creation
 */
async function runSimpleRAGValidation() {
  const startTime = Date.now();

  console.log("ğŸš€ Starting Semantic RAG Validation with Conversation Creation");
  console.log("=".repeat(70));
  console.log(`Assistant ID: ${CONFIG.assistantId}`);
  console.log(`Questions to test: ${BANKING_QUESTIONS.length}`);
  console.log("");

  // Step 1: Create conversations first (if not skipped)
  let createdConversations = [];
  
  if (CONFIG.skipConversationCreation) {
    console.log("ğŸ“‹ Step 1: Skipping conversation creation (using existing conversations)");
    console.log("âš ï¸  WARNING: This assumes conversations already exist for testing");
    // For now, we'll create a placeholder - in real implementation you'd query existing conversations
    createdConversations = [{
      conversationId: `existing-conversation-${Date.now()}`,
      scenario: { type: "existing", title: "Existing conversation" },
      userInput: "Existing conversation for testing",
      existing: true
    }];
  } else {
    console.log("ğŸ“‹ Step 1: Creating conversations...");
    const options = {
      maxCount: CONFIG.maxConversations,
      stage: CONFIG.stage,
      userId: CONFIG.userId,
      preview: CONFIG.preview
    };
    
    console.log(`ğŸ“Š Conversation creation options:`);
    console.log(`   â€¢ Max conversations: ${options.maxCount}`);
    console.log(`   â€¢ Stage: ${options.stage}`);
    console.log(`   â€¢ User ID: ${options.userId}`);
    console.log(`   â€¢ Preview mode: ${options.preview}`);
    console.log("");
    
    createdConversations = await createAllConversations(CONFIG.assistantId, options);
  }
  
  if (!createdConversations || createdConversations.length === 0) {
    throw new Error("Failed to create conversations for testing");
  }

  console.log(`âœ… Created ${createdConversations.length} conversations`);
  console.log("");

  // Apply test count limit if specified
  const conversationsToTest = CONFIG.maxConversationsToTest 
    ? createdConversations.slice(0, CONFIG.maxConversationsToTest)
    : createdConversations;
    
  if (CONFIG.maxConversationsToTest && conversationsToTest.length < createdConversations.length) {
    console.log(`ğŸ¯ Testing only ${conversationsToTest.length} out of ${createdConversations.length} created conversations`);
    console.log("");
  }

  // Step 2: Pre-cache expected answer embeddings for performance
  console.log("ğŸ“‹ Step 2: Pre-caching embeddings...");
  await preCacheExpectedAnswers();
  console.log("");

  const results = {
    timestamp: new Date().toISOString(),
    testConfiguration: CONFIG,
    createdConversations: createdConversations.map(conv => ({
      conversationId: conv.conversationId,
      scenario: conv.scenario,
      userInput: conv.userInput
    })),
    conversationResults: [],
    summary: {
      total_conversations: conversationsToTest.length,
      total_questions: BANKING_QUESTIONS.length * conversationsToTest.length,
      successful_responses: 0,
      average_ai_score: 0,
      scores_8_to_10: 0,
      scores_6_to_7: 0,
      scores_4_to_5: 0,
      scores_1_to_3: 0,
    },
  };

  // Step 3: Test each conversation with all questions
  console.log("ğŸ“‹ Step 3: Running RAG validation tests...");
  
  for (let convIndex = 0; convIndex < conversationsToTest.length; convIndex++) {
    const conversation = conversationsToTest[convIndex];
    
    console.log(`\n${"*".repeat(80)}`);
    console.log(`ğŸ¯ Testing Conversation ${convIndex + 1}/${conversationsToTest.length}`);
    console.log(`ğŸ“± Conversation ID: ${conversation.conversationId}`);
    console.log(`ğŸ‘¤ Customer Type: ${conversation.scenario.type}`);
    console.log(`ğŸ“ User Input: ${conversation.userInput}`);
    console.log(`${"*".repeat(80)}`);
    
    const conversationResult = {
      conversation: {
        conversationId: conversation.conversationId,
        scenario: conversation.scenario,
        userInput: conversation.userInput
      },
      questions: [],
      summary: {
        successful_responses: 0,
        scores_8_to_10: 0,
        scores_6_to_7: 0,
        scores_4_to_5: 0,
        scores_1_to_3: 0
      }
    };

    // Test each question on this conversation
    for (const question of BANKING_QUESTIONS) {
    console.log(`\n${"=".repeat(50)}`);
    console.log(
      `ğŸ“‹ Question ${question.id}: ${question.question.substring(0, 80)}...`
    );
    console.log(`ğŸ“– Expected: ${question.expectedAnswer}`);
    console.log(`ğŸ¯ Test Type: ${question.testType}`);
    console.log(`ğŸ’¡ Purpose: ${question.purpose}`);
    console.log(`${"=".repeat(50)}`);

    const questionResult = {
      question,
      response: null,
      ai_evaluation: null,
      success: false,
    };

    try {
      // Send question to RAG
      const response = await sendRAGQuestion(
        question.question, 
        question.id, 
        conversation.conversationId,
        conversation.userInput
      );
      questionResult.response = response;

      if (response.success && response.content) {
        // Semantic evaluation with AI feedback (no AI scoring)
        console.log(`ğŸ¤– Running semantic evaluation with AI feedback...`);
        const semanticEval = await evaluateWithSemanticSystem(
          question.question,
          question.expectedAnswer,
          response.content
        );

        questionResult.ai_evaluation = semanticEval.ai_evaluation;
        questionResult.semantic_evaluation = semanticEval.semantic_evaluation;
        questionResult.final_score = semanticEval.final_score;
        questionResult.evaluation_breakdown = semanticEval.evaluation_breakdown;
        questionResult.success = true;

        // Display results
        console.log(
          `ğŸ“Š Semantic Similarity: ${semanticEval.semantic_evaluation.similarity} (${semanticEval.semantic_evaluation.score}/10)`
        );
        console.log(`ğŸ† Final Score: ${semanticEval.final_score}/10`);
        console.log(`ğŸ’­ AI Evaluation: ${semanticEval.ai_evaluation.evaluation}`);

        if (semanticEval.semantic_evaluation.numerical_accuracy !== undefined) {
          console.log(
            `ğŸ”¢ Numerical Accuracy: ${semanticEval.semantic_evaluation.numerical_accuracy}`
          );
        }

        if (semanticEval.ai_evaluation.coaching) {
          console.log(`ğŸ“ Coaching: ${semanticEval.ai_evaluation.coaching}`);
        }

        console.log(`ğŸ“ˆ Assessment: ${semanticEval.overall_assessment}`);

        // Update summary based on semantic score
        results.summary.successful_responses++;
        if (semanticEval.final_score >= 8) results.summary.scores_8_to_10++;
        else if (semanticEval.final_score >= 6)
          results.summary.scores_6_to_7++;
        else if (semanticEval.final_score >= 4)
          results.summary.scores_4_to_5++;
        else results.summary.scores_1_to_3++;
      } else {
        console.log(
          `âŒ Failed to get response: ${response.error || "Unknown error"}`
        );
      }
    } catch (error) {
      console.error(`ğŸ’¥ Error in question ${question.id}: ${error.message}`);
      questionResult.error = error.message;
    }

      conversationResult.questions.push(questionResult);

      // Update conversation summary
      if (questionResult.success && questionResult.final_score !== undefined) {
        conversationResult.summary.successful_responses++;
        if (questionResult.final_score >= 8) conversationResult.summary.scores_8_to_10++;
        else if (questionResult.final_score >= 6) conversationResult.summary.scores_6_to_7++;
        else if (questionResult.final_score >= 4) conversationResult.summary.scores_4_to_5++;
        else conversationResult.summary.scores_1_to_3++;
      }

      // Wait between questions
      if (question.id < BANKING_QUESTIONS.length) {
        console.log("â³ Waiting 3 seconds...");
        await new Promise((resolve) => setTimeout(resolve, 3000));
      }
    } // End of question loop

    // Add conversation result to main results
    results.conversationResults.push(conversationResult);
    
    console.log(`\nğŸ“Š Conversation ${convIndex + 1} Summary:`);
    console.log(`â€¢ Questions tested: ${conversationResult.questions.length}`);
    console.log(`â€¢ Successful responses: ${conversationResult.summary.successful_responses}`);
    console.log(`â€¢ Excellent (8-10): ${conversationResult.summary.scores_8_to_10}`);
    console.log(`â€¢ Good (6-7): ${conversationResult.summary.scores_6_to_7}`);
    
    // Wait between conversations
    if (convIndex + 1 < conversationsToTest.length) {
      console.log("â³ Waiting 5 seconds before next conversation...");
      await new Promise((resolve) => setTimeout(resolve, 5000));
    }
  } // End of conversation loop

  // Calculate final summary from all conversations
  const allQuestions = results.conversationResults.flatMap(conv => conv.questions);
  const validResults = allQuestions.filter(
    (q) => q.success && q.final_score !== undefined
  );
  const validFinalScores = validResults.map((q) => q.final_score);
  const validSemanticScores = validResults.map(
    (q) => q.semantic_evaluation?.score || 0
  );

  // Update overall summary totals
  results.summary.successful_responses = validResults.length;
  results.summary.scores_8_to_10 = results.conversationResults.reduce((sum, conv) => sum + conv.summary.scores_8_to_10, 0);
  results.summary.scores_6_to_7 = results.conversationResults.reduce((sum, conv) => sum + conv.summary.scores_6_to_7, 0);
  results.summary.scores_4_to_5 = results.conversationResults.reduce((sum, conv) => sum + conv.summary.scores_4_to_5, 0);
  results.summary.scores_1_to_3 = results.conversationResults.reduce((sum, conv) => sum + conv.summary.scores_1_to_3, 0);

  if (validFinalScores.length > 0) {
    results.summary.average_final_score =
      validFinalScores.reduce((sum, score) => sum + score, 0) /
      validFinalScores.length;
    results.summary.average_semantic_score =
      validSemanticScores.reduce((sum, score) => sum + score, 0) /
      validSemanticScores.length;

    // Calculate semantic similarity stats
    const validSimilarities = validResults
      .map((q) => q.semantic_evaluation?.similarity || 0)
      .filter((sim) => sim > 0);

    if (validSimilarities.length > 0) {
      results.summary.average_similarity =
        validSimilarities.reduce((sum, sim) => sum + sim, 0) /
        validSimilarities.length;
      results.summary.high_similarity_count = validSimilarities.filter(
        (sim) => sim >= 0.8
      ).length;
      results.summary.threshold_met_count = validResults.filter(
        (q) => q.semantic_evaluation?.threshold_met
      ).length;
    }
  }

  // Display final results
  console.log(`\n${"=".repeat(70)}`);
  console.log("ğŸ† SEMANTIC RAG VALIDATION RESULTS (WITH AI FEEDBACK)");
  console.log(`${"=".repeat(70)}`);

  console.log(`\nğŸ“Š Summary:`);
  console.log(`â€¢ Total Conversations: ${results.summary.total_conversations}`);
  console.log(`â€¢ Total Questions: ${results.summary.total_questions}`);
  console.log(
    `â€¢ Successful Responses: ${results.summary.successful_responses}`
  );

  if (results.summary.average_final_score !== undefined) {
    console.log(
      `â€¢ Average Final Score: ${results.summary.average_final_score.toFixed(
        2
      )}/10`
    );
    console.log(
      `â€¢ Average Semantic Score: ${results.summary.average_semantic_score.toFixed(
        2
      )}/10`
    );

    if (results.summary.average_similarity !== undefined) {
      console.log(
        `â€¢ Average Similarity: ${results.summary.average_similarity.toFixed(3)}`
      );
      console.log(
        `â€¢ High Similarity (â‰¥0.8): ${results.summary.high_similarity_count}`
      );
      console.log(
        `â€¢ Threshold Met (â‰¥0.6): ${results.summary.threshold_met_count}`
      );
    }
  }

  console.log(`â€¢ Excellent (8-10): ${results.summary.scores_8_to_10}`);
  console.log(`â€¢ Good (6-7): ${results.summary.scores_6_to_7}`);
  console.log(`â€¢ Fair (4-5): ${results.summary.scores_4_to_5}`);
  console.log(`â€¢ Poor (1-3): ${results.summary.scores_1_to_3}`);

  console.log(`\nğŸ“‹ Conversation Results:`);
  results.conversationResults.forEach((convResult, convIndex) => {
    console.log(`\nğŸ¯ Conversation ${convIndex + 1} (${convResult.conversation.scenario.type}):`);
    console.log(`   Conversation ID: ${convResult.conversation.conversationId}`);
    
    convResult.questions.forEach((result, qIndex) => {
      if (result.success && result.final_score !== undefined) {
        const status = result.final_score >= 6 ? "âœ…" : "âš ï¸";
        const semanticScore = result.semantic_evaluation?.score || 0;
        const similarity = result.semantic_evaluation?.similarity || 0;

        console.log(
          `   ${status} Q${qIndex + 1}. Final: ${result.final_score}/10 ` +
            `(Semantic: ${semanticScore}/10, Sim: ${similarity.toFixed(
              3
            )}) ` +
            `- ${result.question.question.substring(0, 50)}...`
        );
      } else {
        console.log(
          `   âŒ Q${qIndex + 1}. Failed - ${result.question.question.substring(
            0,
            60
          )}...`
        );
      }
    });
  });

  // Overall grade based on final score
  const avgScore = results.summary.average_final_score || 0;
  const overallGrade =
    avgScore >= 8
      ? "EXCELLENT"
      : avgScore >= 6
      ? "GOOD"
      : avgScore >= 4
      ? "FAIR"
      : "NEEDS IMPROVEMENT";

  console.log(`\nğŸ¯ Overall Grade: ${overallGrade}`);

  const executionTime = Date.now() - startTime;
  results.executionTime = `${executionTime}ms`;
  results.overallGrade = overallGrade;

  console.log(`â±ï¸ Execution Time: ${executionTime}ms`);
  console.log("âœ… Semantic RAG validation completed!");

  return results;
}

// Run the validation
if (import.meta.url === `file://${process.argv[1]}`) {
  runSimpleRAGValidation()
    .then((results) => {
      console.log("\nğŸ‰ Semantic RAG validation completed!");

      // Save results to logs
      const logPath = saveTestResults(
        CONFIG.userId,
        "simpleRAGValidation",
        results
      );
      if (logPath) {
        console.log("ğŸ’¾ Results saved to logs directory.");
      }
    })
    .catch((error) => {
      console.error("ğŸ’¥ Validation failed:", error);
      process.exit(1);
    });
}

export { runSimpleRAGValidation };
